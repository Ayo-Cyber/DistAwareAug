{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e1ca66d",
   "metadata": {},
   "source": [
    "# DistAwareAug vs SMOTE Benchmark\n",
    "\n",
    "This notebook compares DistAwareAug with SMOTE (Synthetic Minority Oversampling Technique) on various datasets to demonstrate the advantages of distribution-aware augmentation.\n",
    "\n",
    "## Comparison Metrics:\n",
    "- **Sample Quality**: Distribution similarity, diversity scores\n",
    "- **Classification Performance**: Accuracy, F1-score, AUC-ROC\n",
    "- **Computational Efficiency**: Runtime comparisons\n",
    "- **Visual Analysis**: Sample distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, make_blobs, load_breast_cancer, load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Install imbalanced-learn if not available\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "    print(\"✅ imbalanced-learn found\")\n",
    "except ImportError:\n",
    "    print(\"❌ Installing imbalanced-learn...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"imbalanced-learn\"])\n",
    "    from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "    print(\"✅ imbalanced-learn installed\")\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('.'))))\n",
    "\n",
    "# Import DistAwareAug\n",
    "from distawareaug import DistAwareAugmentor\n",
    "from distawareaug.distance import DistanceMetrics\n",
    "from distawareaug.utils import check_class_balance\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949adf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define comparison framework\n",
    "def evaluate_oversampling_method(X_train, y_train, X_test, y_test, method_name, oversampler, classifier):\n",
    "    \"\"\"Evaluate an oversampling method with a classifier.\"\"\"\n",
    "    \n",
    "    # Time the oversampling\n",
    "    start_time = time.time()\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    oversample_time = time.time() - start_time\n",
    "    \n",
    "    # Time the training\n",
    "    start_time = time.time()\n",
    "    classifier.fit(X_resampled, y_resampled)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred_proba = classifier.predict_proba(X_test)[:, 1] if hasattr(classifier, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # AUC-ROC (for binary classification)\n",
    "    if len(np.unique(y_test)) == 2 and y_pred_proba is not None:\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    else:\n",
    "        auc = None\n",
    "    \n",
    "    # Calculate sample statistics\n",
    "    original_counts = Counter(y_train)\n",
    "    resampled_counts = Counter(y_resampled)\n",
    "    n_synthetic = len(y_resampled) - len(y_train)\n",
    "    \n",
    "    return {\n",
    "        'method': method_name,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'auc_roc': auc,\n",
    "        'oversample_time': oversample_time,\n",
    "        'train_time': train_time,\n",
    "        'total_time': oversample_time + train_time,\n",
    "        'n_synthetic': n_synthetic,\n",
    "        'original_counts': original_counts,\n",
    "        'resampled_counts': resampled_counts,\n",
    "        'X_resampled': X_resampled,\n",
    "        'y_resampled': y_resampled\n",
    "    }\n",
    "\n",
    "print(\"✅ Evaluation framework defined!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
